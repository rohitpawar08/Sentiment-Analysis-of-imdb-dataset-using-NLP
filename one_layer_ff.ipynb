{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxgTufRKpyCoQyfBRW+MFo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19luCqdPXXsQ","executionInfo":{"status":"ok","timestamp":1678724337168,"user_tz":-330,"elapsed":5184,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}},"outputId":"f06e7a3b-2150-4dba-9991-afd7ad6335e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchtext==0.4.0 in /usr/local/lib/python3.9/dist-packages (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.4.0) (1.22.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from torchtext==0.4.0) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.4.0) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.4.0) (2.25.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from torchtext==0.4.0) (1.15.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (2022.12.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.4.0) (4.5.0)\n"]}],"source":["!pip install torchtext==0.4.0"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchtext.datasets import IMDB\n","from torchtext.data import Field, LabelField, BucketIterator"],"metadata":{"id":"hHTawrv3qwpC","executionInfo":{"status":"ok","timestamp":1678724338028,"user_tz":-330,"elapsed":888,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["# Set device to use GPU if available, otherwise use CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"m2cfjHnHqwlm","executionInfo":{"status":"ok","timestamp":1678724338029,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["# Define hyperparameters\n","batch_size = 64\n","num_epochs = 50\n","learning_rate = 0.001\n","hidden_dim = 500"],"metadata":{"id":"TBBykYBcq4Mv","executionInfo":{"status":"ok","timestamp":1678724338029,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["# Define data transforms to preprocess input\n","TEXT = Field(lower=True, batch_first=True)\n","LABEL = LabelField(dtype=torch.float)"],"metadata":{"id":"w4jxj6RAq6vX","executionInfo":{"status":"ok","timestamp":1678724338030,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["train_data, test_data = IMDB.splits(TEXT, LABEL)"],"metadata":{"id":"GCYN-KkCq9F0","executionInfo":{"status":"ok","timestamp":1678724353147,"user_tz":-330,"elapsed":15125,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["TEXT.build_vocab(train_data, max_size=5000)\n","LABEL.build_vocab(train_data)"],"metadata":{"id":"GHJraO8yq_PP","executionInfo":{"status":"ok","timestamp":1678724355671,"user_tz":-330,"elapsed":2584,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["train_loader, test_loader = BucketIterator.splits(\n","    (train_data, test_data), batch_size=batch_size, device=device)"],"metadata":{"id":"vwPmjDdqrBmP","executionInfo":{"status":"ok","timestamp":1678724355673,"user_tz":-330,"elapsed":26,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["# Define neural network architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.embedding = nn.Embedding(len(TEXT.vocab), 100)\n","        self.fc1 = nn.Linear(100, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, 1)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = torch.mean(x, dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = torch.sigmoid(x)\n","        return x.squeeze()"],"metadata":{"id":"k-83I6REqwjF","executionInfo":{"status":"ok","timestamp":1678724355674,"user_tz":-330,"elapsed":24,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["# Create neural network and move it to device\n","net = Net().to(device)"],"metadata":{"id":"lPTPaLLGqwg0","executionInfo":{"status":"ok","timestamp":1678724355678,"user_tz":-330,"elapsed":26,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)"],"metadata":{"id":"1dsXAw6drQ26","executionInfo":{"status":"ok","timestamp":1678724355680,"user_tz":-330,"elapsed":27,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["# Train neural network\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, batch in enumerate(train_loader):\n","        inputs, labels = batch.text.to(device), batch.label.to(device)\n","\n","        # Forward pass\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print statistics\n","        running_loss += loss.item()\n","        if (i+1) % 100 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                  .format(epoch+1, num_epochs, i+1, len(train_loader), running_loss / 100))\n","            running_loss = 0.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsuN3pIkqwej","executionInfo":{"status":"ok","timestamp":1678725187259,"user_tz":-330,"elapsed":831604,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}},"outputId":"3de74f06-39bb-45d8-c7f9-78744ee9b44c"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Step [100/391], Loss: 0.6969\n","Epoch [1/50], Step [200/391], Loss: 0.6972\n","Epoch [1/50], Step [300/391], Loss: 0.6931\n","Epoch [2/50], Step [100/391], Loss: 0.6859\n","Epoch [2/50], Step [200/391], Loss: 0.6763\n","Epoch [2/50], Step [300/391], Loss: 0.6565\n","Epoch [3/50], Step [100/391], Loss: 0.5609\n","Epoch [3/50], Step [200/391], Loss: 0.5324\n","Epoch [3/50], Step [300/391], Loss: 0.4836\n","Epoch [4/50], Step [100/391], Loss: 0.4195\n","Epoch [4/50], Step [200/391], Loss: 0.4034\n","Epoch [4/50], Step [300/391], Loss: 0.3832\n","Epoch [5/50], Step [100/391], Loss: 0.3691\n","Epoch [5/50], Step [200/391], Loss: 0.3568\n","Epoch [5/50], Step [300/391], Loss: 0.3700\n","Epoch [6/50], Step [100/391], Loss: 0.3373\n","Epoch [6/50], Step [200/391], Loss: 0.3366\n","Epoch [6/50], Step [300/391], Loss: 0.3316\n","Epoch [7/50], Step [100/391], Loss: 0.3242\n","Epoch [7/50], Step [200/391], Loss: 0.3036\n","Epoch [7/50], Step [300/391], Loss: 0.3117\n","Epoch [8/50], Step [100/391], Loss: 0.2957\n","Epoch [8/50], Step [200/391], Loss: 0.3043\n","Epoch [8/50], Step [300/391], Loss: 0.2954\n","Epoch [9/50], Step [100/391], Loss: 0.2783\n","Epoch [9/50], Step [200/391], Loss: 0.2910\n","Epoch [9/50], Step [300/391], Loss: 0.2835\n","Epoch [10/50], Step [100/391], Loss: 0.2856\n","Epoch [10/50], Step [200/391], Loss: 0.2812\n","Epoch [10/50], Step [300/391], Loss: 0.2758\n","Epoch [11/50], Step [100/391], Loss: 0.2759\n","Epoch [11/50], Step [200/391], Loss: 0.2542\n","Epoch [11/50], Step [300/391], Loss: 0.2612\n","Epoch [12/50], Step [100/391], Loss: 0.2630\n","Epoch [12/50], Step [200/391], Loss: 0.2619\n","Epoch [12/50], Step [300/391], Loss: 0.2609\n","Epoch [13/50], Step [100/391], Loss: 0.2500\n","Epoch [13/50], Step [200/391], Loss: 0.2427\n","Epoch [13/50], Step [300/391], Loss: 0.2560\n","Epoch [14/50], Step [100/391], Loss: 0.2527\n","Epoch [14/50], Step [200/391], Loss: 0.2428\n","Epoch [14/50], Step [300/391], Loss: 0.2600\n","Epoch [15/50], Step [100/391], Loss: 0.2423\n","Epoch [15/50], Step [200/391], Loss: 0.2297\n","Epoch [15/50], Step [300/391], Loss: 0.2455\n","Epoch [16/50], Step [100/391], Loss: 0.2314\n","Epoch [16/50], Step [200/391], Loss: 0.2400\n","Epoch [16/50], Step [300/391], Loss: 0.2268\n","Epoch [17/50], Step [100/391], Loss: 0.2311\n","Epoch [17/50], Step [200/391], Loss: 0.2314\n","Epoch [17/50], Step [300/391], Loss: 0.2249\n","Epoch [18/50], Step [100/391], Loss: 0.2282\n","Epoch [18/50], Step [200/391], Loss: 0.2236\n","Epoch [18/50], Step [300/391], Loss: 0.2278\n","Epoch [19/50], Step [100/391], Loss: 0.2142\n","Epoch [19/50], Step [200/391], Loss: 0.2277\n","Epoch [19/50], Step [300/391], Loss: 0.2400\n","Epoch [20/50], Step [100/391], Loss: 0.2271\n","Epoch [20/50], Step [200/391], Loss: 0.2070\n","Epoch [20/50], Step [300/391], Loss: 0.2260\n","Epoch [21/50], Step [100/391], Loss: 0.2112\n","Epoch [21/50], Step [200/391], Loss: 0.2224\n","Epoch [21/50], Step [300/391], Loss: 0.2095\n","Epoch [22/50], Step [100/391], Loss: 0.2077\n","Epoch [22/50], Step [200/391], Loss: 0.2137\n","Epoch [22/50], Step [300/391], Loss: 0.2113\n","Epoch [23/50], Step [100/391], Loss: 0.2040\n","Epoch [23/50], Step [200/391], Loss: 0.2032\n","Epoch [23/50], Step [300/391], Loss: 0.2193\n","Epoch [24/50], Step [100/391], Loss: 0.2213\n","Epoch [24/50], Step [200/391], Loss: 0.2077\n","Epoch [24/50], Step [300/391], Loss: 0.2090\n","Epoch [25/50], Step [100/391], Loss: 0.2246\n","Epoch [25/50], Step [200/391], Loss: 0.1927\n","Epoch [25/50], Step [300/391], Loss: 0.1981\n","Epoch [26/50], Step [100/391], Loss: 0.1870\n","Epoch [26/50], Step [200/391], Loss: 0.2041\n","Epoch [26/50], Step [300/391], Loss: 0.2039\n","Epoch [27/50], Step [100/391], Loss: 0.1960\n","Epoch [27/50], Step [200/391], Loss: 0.2058\n","Epoch [27/50], Step [300/391], Loss: 0.2234\n","Epoch [28/50], Step [100/391], Loss: 0.1935\n","Epoch [28/50], Step [200/391], Loss: 0.1985\n","Epoch [28/50], Step [300/391], Loss: 0.1998\n","Epoch [29/50], Step [100/391], Loss: 0.1951\n","Epoch [29/50], Step [200/391], Loss: 0.1924\n","Epoch [29/50], Step [300/391], Loss: 0.1990\n","Epoch [30/50], Step [100/391], Loss: 0.2056\n","Epoch [30/50], Step [200/391], Loss: 0.1910\n","Epoch [30/50], Step [300/391], Loss: 0.1901\n","Epoch [31/50], Step [100/391], Loss: 0.1769\n","Epoch [31/50], Step [200/391], Loss: 0.1893\n","Epoch [31/50], Step [300/391], Loss: 0.1917\n","Epoch [32/50], Step [100/391], Loss: 0.2011\n","Epoch [32/50], Step [200/391], Loss: 0.1824\n","Epoch [32/50], Step [300/391], Loss: 0.1959\n","Epoch [33/50], Step [100/391], Loss: 0.1687\n","Epoch [33/50], Step [200/391], Loss: 0.1950\n","Epoch [33/50], Step [300/391], Loss: 0.1931\n","Epoch [34/50], Step [100/391], Loss: 0.1973\n","Epoch [34/50], Step [200/391], Loss: 0.1917\n","Epoch [34/50], Step [300/391], Loss: 0.1749\n","Epoch [35/50], Step [100/391], Loss: 0.1754\n","Epoch [35/50], Step [200/391], Loss: 0.1921\n","Epoch [35/50], Step [300/391], Loss: 0.1883\n","Epoch [36/50], Step [100/391], Loss: 0.1851\n","Epoch [36/50], Step [200/391], Loss: 0.1751\n","Epoch [36/50], Step [300/391], Loss: 0.1780\n","Epoch [37/50], Step [100/391], Loss: 0.1750\n","Epoch [37/50], Step [200/391], Loss: 0.1740\n","Epoch [37/50], Step [300/391], Loss: 0.1902\n","Epoch [38/50], Step [100/391], Loss: 0.1736\n","Epoch [38/50], Step [200/391], Loss: 0.1772\n","Epoch [38/50], Step [300/391], Loss: 0.1870\n","Epoch [39/50], Step [100/391], Loss: 0.1668\n","Epoch [39/50], Step [200/391], Loss: 0.1729\n","Epoch [39/50], Step [300/391], Loss: 0.1665\n","Epoch [40/50], Step [100/391], Loss: 0.1700\n","Epoch [40/50], Step [200/391], Loss: 0.1990\n","Epoch [40/50], Step [300/391], Loss: 0.1691\n","Epoch [41/50], Step [100/391], Loss: 0.1661\n","Epoch [41/50], Step [200/391], Loss: 0.1735\n","Epoch [41/50], Step [300/391], Loss: 0.1857\n","Epoch [42/50], Step [100/391], Loss: 0.1773\n","Epoch [42/50], Step [200/391], Loss: 0.1637\n","Epoch [42/50], Step [300/391], Loss: 0.1757\n","Epoch [43/50], Step [100/391], Loss: 0.1681\n","Epoch [43/50], Step [200/391], Loss: 0.1626\n","Epoch [43/50], Step [300/391], Loss: 0.1849\n","Epoch [44/50], Step [100/391], Loss: 0.1768\n","Epoch [44/50], Step [200/391], Loss: 0.1653\n","Epoch [44/50], Step [300/391], Loss: 0.1853\n","Epoch [45/50], Step [100/391], Loss: 0.1691\n","Epoch [45/50], Step [200/391], Loss: 0.1662\n","Epoch [45/50], Step [300/391], Loss: 0.1812\n","Epoch [46/50], Step [100/391], Loss: 0.1599\n","Epoch [46/50], Step [200/391], Loss: 0.1681\n","Epoch [46/50], Step [300/391], Loss: 0.1837\n","Epoch [47/50], Step [100/391], Loss: 0.1856\n","Epoch [47/50], Step [200/391], Loss: 0.1633\n","Epoch [47/50], Step [300/391], Loss: 0.1701\n","Epoch [48/50], Step [100/391], Loss: 0.1502\n","Epoch [48/50], Step [200/391], Loss: 0.1759\n","Epoch [48/50], Step [300/391], Loss: 0.1748\n","Epoch [49/50], Step [100/391], Loss: 0.1660\n","Epoch [49/50], Step [200/391], Loss: 0.1659\n","Epoch [49/50], Step [300/391], Loss: 0.1739\n","Epoch [50/50], Step [100/391], Loss: 0.1556\n","Epoch [50/50], Step [200/391], Loss: 0.1580\n","Epoch [50/50], Step [300/391], Loss: 0.1691\n"]}]},{"cell_type":"code","source":["# Define file path to save the trained model\n","model_path = 'one_layer_FFNN_model.pt'\n","\n","# Save trained model\n","torch.save(net.state_dict(), model_path)"],"metadata":{"id":"It70ewB00nuJ","executionInfo":{"status":"ok","timestamp":1678725285644,"user_tz":-330,"elapsed":640,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["# Test neural network\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for batch in test_loader:\n","        inputs, labels = batch.text.to(device), batch.label.to(device)\n","        outputs = net(inputs)\n","        predicted = torch.round(outputs)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the {} test reviews: {} %'.format(total, 100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hnPvgjEqwbs","executionInfo":{"status":"ok","timestamp":1678725293380,"user_tz":-330,"elapsed":3312,"user":{"displayName":"Rohit Pawar","userId":"12919547114576022349"}},"outputId":"b77c2106-2d67-433e-b43f-9ee4714e5c66"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy of the model on the 25000 test reviews: 85.96 %\n"]}]}]}