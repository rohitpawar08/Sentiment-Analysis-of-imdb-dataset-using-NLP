{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:55:35.943858Z",
     "iopub.status.busy": "2023-06-07T13:55:35.943507Z",
     "iopub.status.idle": "2023-06-07T13:55:41.576552Z",
     "shell.execute_reply": "2023-06-07T13:55:41.575574Z",
     "shell.execute_reply.started": "2023-06-07T13:55:35.943824Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-06-07T13:55:41.578813Z",
     "iopub.status.busy": "2023-06-07T13:55:41.578418Z",
     "iopub.status.idle": "2023-06-07T13:55:42.916008Z",
     "shell.execute_reply": "2023-06-07T13:55:42.915166Z",
     "shell.execute_reply.started": "2023-06-07T13:55:41.578776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47223</th>\n",
       "      <td>Plotwise this is a rather silly little whodunn...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "47223  Plotwise this is a rather silly little whodunn...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with BERT\n",
    "We will do the following operations to train a sentiment analysis model:\n",
    "* Install Transformers library;\n",
    "* Load the BERT Classifier and Tokenizer alıng with Input modules;\n",
    "* Download the IMDB Reviews Data and create a processed dataset (this will take several operations;\n",
    "* Configure the Loaded BERT model and Train for Fine-tuning\n",
    "* Make Predictions with the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:55:42.917860Z",
     "iopub.status.busy": "2023-06-07T13:55:42.917497Z",
     "iopub.status.idle": "2023-06-07T13:55:51.614638Z",
     "shell.execute_reply": "2023-06-07T13:55:51.613550Z",
     "shell.execute_reply.started": "2023-06-07T13:55:42.917821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.9.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.94)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing Transformers library\n",
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:55:51.616962Z",
     "iopub.status.busy": "2023-06-07T13:55:51.616563Z",
     "iopub.status.idle": "2023-06-07T13:56:18.252092Z",
     "shell.execute_reply": "2023-06-07T13:56:18.251073Z",
     "shell.execute_reply.started": "2023-06-07T13:55:51.616919Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d9d458e45b4351b9b1a24a63a539a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bdd648b22a4112862f356bad87eed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'dropout_37']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d2a3f678c742f9b9b9ce14e3b2c547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the BERT Classifier and Tokenizer along with Input module\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:18.255060Z",
     "iopub.status.busy": "2023-06-07T13:56:18.254442Z",
     "iopub.status.idle": "2023-06-07T13:56:18.289460Z",
     "shell.execute_reply": "2023-06-07T13:56:18.288733Z",
     "shell.execute_reply.started": "2023-06-07T13:56:18.255016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:39.687429Z",
     "iopub.status.busy": "2023-06-07T13:56:39.686962Z",
     "iopub.status.idle": "2023-06-07T13:56:39.788664Z",
     "shell.execute_reply": "2023-06-07T13:56:39.787612Z",
     "shell.execute_reply.started": "2023-06-07T13:56:39.687385Z"
    }
   },
   "outputs": [],
   "source": [
    "# changing positive and negative into numeric values\n",
    "\n",
    "def cat2num(value):\n",
    "    if value=='positive': \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "df['sentiment']  =  df['sentiment'].apply(cat2num)\n",
    "train = df[:45000]\n",
    "test = df[45000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "For training model with BERT, we need to do some additional Prepriocessing. Let's understand them one by one!\n",
    "* Add special tokens to separate sentences and do classification\n",
    "* Pass sequences of constant length (introduce padding)\n",
    "* Create array of 0s (pad token) and 1s (real token) called attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:41.891311Z",
     "iopub.status.busy": "2023-06-07T13:56:41.890949Z",
     "iopub.status.idle": "2023-06-07T13:56:41.899078Z",
     "shell.execute_reply": "2023-06-07T13:56:41.897981Z",
     "shell.execute_reply.started": "2023-06-07T13:56:41.891268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'this', 'ka', '##ggle', 'notebook', ',', 'i', 'will', 'do', 'sentiment', 'analysis', 'using', 'bert', 'with', 'hugging', '##face']\n",
      "[1999, 2023, 10556, 24679, 14960, 1010, 1045, 2097, 2079, 15792, 4106, 2478, 14324, 2007, 17662, 12172]\n"
     ]
    }
   ],
   "source": [
    "# But first see BERT tokenizer exmaples and other required stuff!\n",
    "\n",
    "example='In this Kaggle notebook, I will do sentiment analysis using BERT with Huggingface'\n",
    "tokens=tokenizer.tokenize(example)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Tokens\n",
    "* [SEP] - marker for ending of a sentence\n",
    "* [CLS] - we must add this token to the start of each sentence, so BERT knows we’re doing classification\n",
    "* [PAD] -There is also a special token for padding:\n",
    "* [UNK] - ERT understands tokens that were in the training set. Everything else can be encoded using the [UNK] (unknown) token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:43.773826Z",
     "iopub.status.busy": "2023-06-07T13:56:43.773462Z",
     "iopub.status.idle": "2023-06-07T13:56:44.882839Z",
     "shell.execute_reply": "2023-06-07T13:56:44.881903Z",
     "shell.execute_reply.started": "2023-06-07T13:56:43.773790Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, review, sentiment): \n",
    "    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[review], \n",
    "                                                          label = x[sentiment]), axis = 1)\n",
    "\n",
    "    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[review], \n",
    "                                                          label = x[sentiment]), axis = 1,)\n",
    "  \n",
    "    return train_InputExamples, validation_InputExamples\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train,  test, 'review',  'sentiment')\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:44.886025Z",
     "iopub.status.busy": "2023-06-07T13:56:44.885395Z",
     "iopub.status.idle": "2023-06-07T13:56:44.892223Z",
     "shell.execute_reply": "2023-06-07T13:56:44.891360Z",
     "shell.execute_reply.started": "2023-06-07T13:56:44.885982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputExample(guid=None, text_a=\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\", text_b=None, label=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:45.834131Z",
     "iopub.status.busy": "2023-06-07T13:56:45.833785Z",
     "iopub.status.idle": "2023-06-07T13:56:45.848255Z",
     "shell.execute_reply": "2023-06-07T13:56:45.847288Z",
     "shell.execute_reply.started": "2023-06-07T13:56:45.834096Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in tqdm(examples):\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,    # Add 'CLS' and 'SEP'\n",
    "            max_length=max_length,    # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "        features.append(InputFeatures( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label) )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T13:56:47.171039Z",
     "iopub.status.busy": "2023-06-07T13:56:47.170690Z",
     "iopub.status.idle": "2023-06-07T14:04:03.987709Z",
     "shell.execute_reply": "2023-06-07T14:04:03.986758Z",
     "shell.execute_reply.started": "2023-06-07T13:56:47.171005Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45000 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 45000/45000 [07:16<00:00, 103.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T14:13:18.151151Z",
     "iopub.status.busy": "2023-06-07T14:13:18.150753Z",
     "iopub.status.idle": "2023-06-07T14:14:06.174393Z",
     "shell.execute_reply": "2023-06-07T14:14:06.173248Z",
     "shell.execute_reply.started": "2023-06-07T14:13:18.151116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:47<00:00, 104.20it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our dataset containing processed input sequences are ready to be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T14:14:06.176620Z",
     "iopub.status.busy": "2023-06-07T14:14:06.176181Z",
     "iopub.status.idle": "2023-06-07T14:14:06.206492Z",
     "shell.execute_reply": "2023-06-07T14:14:06.205647Z",
     "shell.execute_reply.started": "2023-06-07T14:14:06.176582Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T14:17:30.362923Z",
     "iopub.status.busy": "2023-06-07T14:17:30.362522Z",
     "iopub.status.idle": "2023-06-07T15:04:05.597297Z",
     "shell.execute_reply": "2023-06-07T15:04:05.596266Z",
     "shell.execute_reply.started": "2023-06-07T14:17:30.362885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2814/2814 [==============================] - 1388s 493ms/step - loss: 0.2417 - accuracy: 0.8987 - val_loss: 0.2820 - val_accuracy: 0.8940\n",
      "Epoch 2/2\n",
      "2814/2814 [==============================] - 1384s 492ms/step - loss: 0.0707 - accuracy: 0.9759 - val_loss: 0.4067 - val_accuracy: 0.8970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x78d5e7968a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T15:04:10.046411Z",
     "iopub.status.busy": "2023-06-07T15:04:10.046030Z",
     "iopub.status.idle": "2023-06-07T15:04:10.051872Z",
     "shell.execute_reply": "2023-06-07T15:04:10.050704Z",
     "shell.execute_reply.started": "2023-06-07T15:04:10.046377Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_sentences = ['worst movie of my life, will never watch movies from this series', 'Wow, blew my mind, what a movie by Marvel, animation and story is amazing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T15:04:14.775856Z",
     "iopub.status.busy": "2023-06-07T15:04:14.775420Z",
     "iopub.status.idle": "2023-06-07T15:04:14.886858Z",
     "shell.execute_reply": "2023-06-07T15:04:14.885880Z",
     "shell.execute_reply.started": "2023-06-07T15:04:14.775809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst movie of my life, will never watch movies from this series :  Negative\n",
      "Wow, blew my mind, what a movie by Marvel, animation and story is amazing :  Positive\n"
     ]
    }
   ],
   "source": [
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')   # we are tokenizing before sending into our trained model\n",
    "tf_outputs = model(tf_batch)                                  \n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)       # axis=-1, this means that the index that will be returned by argmax will be taken from the *last* axis.\n",
    "labels = ['Negative','Positive']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(pred_sentences)):\n",
    "    print(pred_sentences[i], \": \", labels[label[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
